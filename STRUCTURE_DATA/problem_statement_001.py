# -*- coding: utf-8 -*-
"""problem statement 001.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19zA5ohAzB49Kg7E8_3UDU4MugNave0-3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
from sklearn.utils import shuffle

from google.colab import drive
drive.mount('/content/drive')

ds_train=pd.read_parquet("/content/drive/MyDrive/structure data assignment/New folder/train.parquet")
ds_train.head()

ds_train['Date']=[pd.to_datetime(x) for x in ds_train['Date']]

ds_train.reset_index(inplace=True,drop=True)
ds_train

len(ds_train)

ds_train.columns

target_index=ds_train[ds_train['Incident']=='TARGET DRUG']['Patient-Uid'].unique()
new_df

target_index

len(ds_train)

ds_train.nunique()

new_df=ds_train.iloc[0:0]

new_df

train_copy=ds_train.copy()

train_copy

train_copy.sort_values(by=['Patient-Uid','Date'],inplace=True)

df=dict(list(train_copy.groupby('Patient-Uid')))

p=df['a0dc93f2-1c7c-11ec-9cd2-16262ee38c7f']
p.columns

for i in df.keys():
  df[i].set_index(df[i]['Date'],drop=True,inplace=True)

"""##Finding Patients  in a given Target drug"""

for i in df.keys():
  if i in target_index:
   for j in list(df[i].index):
     tra_dat=list(df[i][df[i]['Incident']=='TARGET DRUG'].Date)[0]
     date=list(pd.date_range(end=tra_dat,periods=30,freq='D'))
     if j in date:
       t=df[i].loc[:j,:]
   new_df=pd.concat([new_df,t],ignore_index=True)

new_df

new_df1=pd.get_dummies(new_df['Incident'])
new_df1

new_df1=pd.concat([new_df,new_df1],axis=1)

new_df1.drop(['Incident','Date','TARGET DRUG'],axis=1,inplace=True)
new_df1

col=list(new_df1.columns[1:])

new_df1=new_df1.groupby('Patient-Uid')[col].sum()

new_df1['Target Drug']=1

new_df1

"""##Finding Patients not in a given Target drug"""

nontarget=ds_train.iloc[0:0]

nontarget

for i in df.keys():
  if i not in target_index:
     g=df[i]
     nontarget=pd.concat([nontarget,g],ignore_index=True)

nontarget

non_target=pd.get_dummies(nontarget['Incident'])

non_target=pd.concat([nontarget,non_target],axis=1)

non_target.drop(['Incident','Date'],axis=1,inplace=True)
col1=list(non_target.columns[1:])
non_target=non_target.groupby('Patient-Uid')[col1].sum()

non_target['Target Drug']=0

non_target

"""##Dataframe with both Patients given Target drug and not given target drug"""

Patient_df=pd.concat([new_df1,non_target])

Patient_df.fillna(0.0,inplace=True)

Patient_df.info()

Patient_df.reset_index(inplace=True)

Patient_df=shuffle(Patient_df)
Patient_df.reset_index(inplace=True,drop=True)

Patient_df

l=[len(Patient_df[Patient_df['Target Drug']==1]),len(Patient_df[Patient_df['Target Drug']==0])]

"""##Plotting counts of patients given target drug and not given target drug"""

Patient_df['Target Drug'].value_counts()

fig = plt.figure(figsize = (5, 5))
# creating the bar plot
plt.bar(['Targetdrug','Non_target'], l, color ='maroon',width = 0.4)
plt.text(x=-.1,y=l[0]+ 200, s=str(l[0]))
plt.text(x=0.9,y=l[1]+ 200, s=str(l[1]))
plt.ylim(0,20000)
plt.show()

Patient_df.corr()['Target Drug']

"""##Importing Test Dataset for prediction"""

test_df=pd.read_parquet('/content/drive/MyDrive/structure data assignment/New folder/test.parquet')
test_df

test_df['Incident'].unique()

test_dum=pd.get_dummies(test_df['Incident'])
    
test_copy=test_df.copy()
     
test_copy=pd.concat([test_copy,test_dum],axis=1)
     
test_copy.drop(['Date','Incident'],inplace=True,axis=1)
     
test_col=list(test_copy.columns[1:])
     
test_copy=test_copy.groupby('Patient-Uid')[test_col].sum().reset_index()

test_copy

"""##Preparing Train and Test Data for model perparation"""

T_list=list(test_copy.columns[1:])
     
test_x=test_copy[T_list]
     
x_train=Patient_df[T_list]

y_train=Patient_df["Target Drug"]

"""##Train and Test split"""

from sklearn.model_selection import train_test_split
    
x_train, x_test, y_train, y_test = train_test_split(x_train,y_train,test_size=0.40,random_state=107)

"""#Model Creation"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)
test_x= sc.fit_transform(test_x)

"""##Creating Model Using Tensorflow"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Activation
from tensorflow.keras.optimizers import Adam,RMSprop,SGD

model = Sequential()
model.add(Dense(23))
model.add(Dense(16,activation='relu'))
model.add(Dense(16,activation='relu'))
model.add(Dense(8,activation='relu'))
model.add(Dense(8,activation='relu'))
model.add(Dense(1,activation ='sigmoid'))

model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])
model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test),batch_size=250 , epochs=100)

model.summary()

"""#Evaluation With F1 Score

"""

from sklearn.metrics import classification_report,confusion_matrix
     
prediction = model.predict(x_test)
prediction

print(classification_report(y_test,prediction.round()))

"""##Predicting for Test Dataset given"""

test_pred=model.predict(test_x)
test_y=test_pred.round()
test_y

test_copy['label']=test_y
     
test_copy=test_copy.astype({'label':'int'})
     
output_df=test_copy[['Patient-Uid','label']]
     
output_df

output_df['label'].value_counts()

output_df.to_csv('final_submission.csv')